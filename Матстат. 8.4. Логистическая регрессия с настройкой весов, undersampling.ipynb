{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В 6 модуле мы обучали логистическую регрессию для классификации людей в группу риска ишемической болезни сердца в 10-летней перспрективе по датасету framingham.csv.\n",
    "\n",
    "Если вы помните, модель получилась плохая: несмотря на довольно большую долю верно классифицированных пациентов (около 85%), она очень плохо определяла пациентов группы риска. Чувствительность была нулевая или почти нулевая, а ошибка 2 рода (ложно-отрицательные результаты среди пациентов группы риска) большая.\n",
    "\n",
    "Для медицинского теста это плохо, так как врач пропустит много пациентов с высоким риском заболеть.\n",
    "\n",
    "Проблема заключается вот в чем: в обучающей выборке здоровых пациентов намного больше, чем больных. В этом случае классификатору \"выгодно\" обучиться так, чтобы хорошо определять бОльший класс, так как он тогда чаще будет угадывать.\n",
    "\n",
    "Попробуем улучшить работу классификатора двумя способами: настроив веса в логистической регрессии и сделав undersampling здоровых пациентов в обучающей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем датасет и избавимся от нулевых строк\n",
    "df = pd.read_csv('framingham.xls')\n",
    "df.dropna(axis=0,inplace=True) #избавляемся от строчек с пропущенными значениями\n",
    "\n",
    "# разбиваем датафрейм на две части, dfx - параметры, dfy - целевая переменная. \n",
    "dfx = df.drop('TenYearCHD', axis = 1)\n",
    "dfy = df[['TenYearCHD']] \n",
    "\n",
    "# разбиваем датасет на train и test выборку в соотношениии 80% train / 20% test случайным образом\n",
    "# фиксируем random_state\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfx, dfy, test_size=0.2, random_state=17) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Способ\n",
    "\n",
    "Его идея заключается в том, что мы добавим на этапе обучения бОльший штраф за ошибки для более редкого класса, тем самым увеличивая чувствительность классификатора к этому классу. \n",
    "\n",
    "Среди параметров LogisticRegression есть class_weight. Он может иметь 3 состояния:\n",
    "\n",
    "1. class_weight=None означает, что мы обучаем регрессию как обычно, без доп. настроек. Так мы делали в практике 6 модуля \n",
    "2. class_weight='balanced' задает веса обратно пропорционально количеству элементов в каждом классе. Например, если в выборке будет 1000 здоровых пациентов и 100 больных, то веса будут относиться как 1:10. В описании параметров на https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression есть формула, по которой считаются коэффициенты.\n",
    "3. class_weight=dict - можно задать веса самостоятельно с формате словаря."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала давайте попробуем, как работает логистическая регрессия с весами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.LogisticRegression(solver='liblinear', class_weight='balanced') \n",
    "# обучаем\n",
    "model = lm.fit(X_train, y_train.values.ravel()) \n",
    "# сделаем prediction классов на всей тестовой выборке\n",
    "y_pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[410, 209],\n",
       "       [ 35,  78]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# строим confusion matrix - таблицу правильных и неправильных предсказаний\n",
    "# можно увидеть, что она ведет себя намного лучше, чем для модели без весов!\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видите, мы сущесвтенно улучшили чувствительность классификатора.\n",
    "\n",
    "Давайте посмотрим на метрики качества:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6666666666666666\n",
      "Sensitivity:  0.6902654867256637\n",
      "Specificity:  0.6623586429725363\n",
      "Pricision:  0.27177700348432055\n",
      "Type I error rate:  0.3376413570274637\n",
      "Type II error rate:  0.30973451327433627\n"
     ]
    }
   ],
   "source": [
    "TN = cnf_matrix[0,0] # True Negative\n",
    "TP = cnf_matrix[1,1] # True Positive\n",
    "FN = cnf_matrix[1,0] # False Negative\n",
    "FP = cnf_matrix[0,1] # False Positive\n",
    "    \n",
    "Ac = lm.score(X_test, y_test)\n",
    "Sens = TP/(TP+FN) \n",
    "Sp = TN/(TN+FP)\n",
    "P = TP/(TP+FP)\n",
    "typeI = FP/(FP+TN)\n",
    "typeII = FN/(FN+TP)\n",
    "    \n",
    "print('Accuracy: ', Ac)\n",
    "print('Sensitivity: ', Sens)\n",
    "print('Specificity: ', Sp)\n",
    "print('Pricision: ', P)\n",
    "print('Type I error rate: ', typeI)\n",
    "print('Type II error rate: ', typeII)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy модели стала меньше, чем в простом случае, но зато ошибка второго рода тоже уменьшилась, что для нас в данном случае важнее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтобы не делать 100500 копипастов, создадим функцию print_logit_scores\n",
    "# которая будет обучать регрессию заданным способом и выводить разные метрики качества\n",
    "\n",
    "def print_logit_scores(data_train, target_train, data_test, target_test, model_type, weights):\n",
    "    \n",
    "    # data_train, target_train, data_test, target_test - это обучающие и тестовые данные\n",
    "    # model_type задает один из 3 типов обучения: 'n' - None, 'b' - balanced, 'w' - заданные пользователем веса\n",
    "    # w - вектор весов. Используется только для model_type = 'w'\n",
    "    \n",
    "    if (model_type == 'n'): # обучаем с равными весами\n",
    "        lm = linear_model.LogisticRegression(solver='liblinear', class_weight=None)    \n",
    "    elif (model_type == 'b'): # балансируем веса, как предлагают разработчики sklearn\n",
    "        lm = linear_model.LogisticRegression(solver='liblinear', class_weight='balanced')\n",
    "    elif (model_type == 'w'): # балансируем веса самостоятельно\n",
    "        lm = linear_model.LogisticRegression(solver='liblinear', class_weight={0:weights[0], 1:weights[1]}) \n",
    "\n",
    "    # обучаем\n",
    "    model = lm.fit(data_train, target_train.values.ravel()) \n",
    "\n",
    "    # сделаем prediction классов на всей тестовой выборке\n",
    "    target_pred = lm.predict(data_test)\n",
    "\n",
    "    # строим confusion matrix - таблицу правильных и неправильных предсказаний\n",
    "    cnf_matrix = metrics.confusion_matrix(target_test, target_pred)\n",
    "\n",
    "    TN = cnf_matrix[0,0] # True Negative\n",
    "    TP = cnf_matrix[1,1] # True Positive\n",
    "    FN = cnf_matrix[1,0] # False Negative\n",
    "    FP = cnf_matrix[0,1] # False Positive\n",
    "    \n",
    "    Ac = lm.score(data_test, target_test)\n",
    "    Sens = TP/(TP+FN) \n",
    "    Sp = TN/(TN+FP)\n",
    "    P = TP/(TP+FP)\n",
    "    typeI = FP/(FP+TN)\n",
    "    typeII = FN/(FN+TP)\n",
    "    \n",
    "    print('Accuracy: ', Ac)\n",
    "    print('Sensitivity: ', Sens)\n",
    "    print('Specificity: ', Sp)\n",
    "    print('Precision: ', P)\n",
    "    print('Type I error rate: ', typeI)\n",
    "    print('Type II error rate: ', typeII)\n",
    "    \n",
    "    return [Ac,Sens,Sp,P,typeI,typeII] # возвращаем список метрик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "интуитивно хочется поделить веса обратно пропорционально количеству элементов в классе, оставив сумму 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15174299, 0.84825701])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "share = y_train['TenYearCHD'].value_counts()\n",
    "w0 = share[1]/(share[0]+share[1])\n",
    "w = np.array([w0,1-w0])\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "разработчики sklearn предлагают балансировать веса по другому правилу. При этом они тоже будут обратно пропорциональны количествую элементов, но сумма будет уже не 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.589444  , 3.29504505])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_train['TenYearCHD']) # считает количество вхождений 0 и 1 в y_train['TenYearCHD']\n",
    "w_b = y_train.shape[0]/ (2*np.bincount(y_train['TenYearCHD']))\n",
    "w_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "отношение интуитивных весов:  0.17888799355358584\n",
      "отношение balanced весов:  0.17888799355358584\n"
     ]
    }
   ],
   "source": [
    "# Давайте убедимся, что отношения весов действительно одинаковые\n",
    "# При этом бОльший по размеру класс (нулевой, то есть здоровые пациенты) имеет мЕньший вес\n",
    "print('отношение интуитивных весов: ', w[0]/w[1])\n",
    "print('отношение balanced весов: ', w_b[0]/w_b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ручная балансировка по правилу balanced\n",
      "Accuracy:  0.6666666666666666\n",
      "Sensitivity:  0.6902654867256637\n",
      "Specificity:  0.6623586429725363\n",
      "Precision:  0.27177700348432055\n",
      "Type I error rate:  0.3376413570274637\n",
      "Type II error rate:  0.30973451327433627\n",
      "\n",
      "\n",
      "встроенная балансировка по правилу balanced\n",
      "Accuracy:  0.6666666666666666\n",
      "Sensitivity:  0.6902654867256637\n",
      "Specificity:  0.6623586429725363\n",
      "Precision:  0.27177700348432055\n",
      "Type I error rate:  0.3376413570274637\n",
      "Type II error rate:  0.30973451327433627\n",
      "\n",
      "\n",
      "без балансировки весов\n",
      "Accuracy:  0.855191256830601\n",
      "Sensitivity:  0.07964601769911504\n",
      "Specificity:  0.9967689822294022\n",
      "Precision:  0.8181818181818182\n",
      "Type I error rate:  0.0032310177705977385\n",
      "Type II error rate:  0.9203539823008849\n"
     ]
    }
   ],
   "source": [
    "# сравним \n",
    "print('ручная балансировка по правилу balanced')\n",
    "m1 = print_logit_scores(X_train, y_train, X_test, y_test, 'w', w_b) # ручная балансировка по правилу balanced\n",
    "print('\\n')\n",
    "print ('встроенная балансировка по правилу balanced')\n",
    "m2 = print_logit_scores(X_train, y_train, X_test, y_test, 'b', w) # встроенная балансировка по правилу balanced\n",
    "print('\\n')\n",
    "print ('без балансировки весов')\n",
    "m3 = print_logit_scores(X_train, y_train, X_test, y_test, 'n', w) # без балансировки весов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Способ\n",
    "\n",
    "Его идея заключается в том, чтобы уравнять доли \"здоровых\" и \"больных\" в обучающей выборке.\n",
    "\n",
    "Каким образом?\n",
    "\n",
    "Очень просто: из всех \"здоровых\" пациентов в обучающей выборке сделам подвыборку того же размера, сколько у нас \"больных\". Например, если в обучающей выборке 1000 \"здоровых\" и 100 \"больных\", то мы из этой 1000 случайным образом выберем 100. Это называется undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge imbalanced-learn    #попытки установить библиотеку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading https://files.pythonhosted.org/packages/81/a7/4179e6ebfd654bd0eac0b9c06125b8b4c96a9d0a8ff9e9507eb2a26d2d7e/imblearn-0.0-py2.py3-none-any.whl\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/62/08c14224a7e242df2cef7b312d2ef821c3931ec9b015ff93bb52ec8a10a3/imbalanced_learn-0.5.0-py3-none-any.whl (173kB)\n",
      "Collecting scikit-learn>=0.21 (from imbalanced-learn->imblearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/d6/9e/6a42486ffa64711fb868e5d4a9167153417e7414c3d8d3e0d627cf391e1e/scikit_learn-0.21.3-cp37-cp37m-win_amd64.whl (5.9MB)\n",
      "Requirement already satisfied: scipy>=0.17 in d:\\datascience\\anaconda\\lib\\site-packages (from imbalanced-learn->imblearn) (1.2.1)\n",
      "Collecting joblib>=0.11 (from imbalanced-learn->imblearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\n",
      "Requirement already satisfied: numpy>=1.11 in d:\\datascience\\anaconda\\lib\\site-packages (from imbalanced-learn->imblearn) (1.16.2)\n",
      "Installing collected packages: joblib, scikit-learn, imbalanced-learn, imblearn\n",
      "  Found existing installation: scikit-learn 0.20.3\n",
      "    Uninstalling scikit-learn-0.20.3:\n",
      "      Successfully uninstalled scikit-learn-0.20.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not install packages due to an EnvironmentError: [WinError 5] Отказано в доступе: 'd:\\\\datascience\\\\anaconda\\\\lib\\\\site-packages\\\\~klearn\\\\__check_build\\\\_check_build.cp37-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn --user    #попытки установить библиотеку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-d7e1d98da16e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# в моей версии Anaconda (2019.03) она не предустановлена\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# возможно, вам тоже нужно установить ее самостоятельно\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munder_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomUnderSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "# Нам понадобится новая библиотека imblearn\n",
    "# в моей версии Anaconda (2019.03) она не предустановлена\n",
    "# возможно, вам тоже нужно установить ее самостоятельно\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# освежите в памяти, что показывает share и что значит share[1]\n",
    "# параметр ratio в RandomUnderSampler задается словарем: \n",
    "# 1: - желаемое количество объектов класса 1\n",
    "# 0: - желаемое количество объектов класса 0\n",
    "\n",
    "# задаем параметры выборки:\n",
    "sampler = RandomUnderSampler(ratio={1: share[1], 0: share[1]})\n",
    "\n",
    "# сам unpersampling выполняется здесь:\n",
    "X_train_under_np, y_train_under_np = sampler.fit_sample(X_train, y_train)\n",
    "\n",
    "# преобразуем в DataFrame, чтобы скормить логистической регрессии\n",
    "X_train_under = pd.DataFrame(X_train_under_np)\n",
    "y_train_under = pd.DataFrame(y_train_under_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вычисляем качество модели с undersampling\n",
    "# как вы думаете, почему в качестве model_type здесь можно взять 'n'?\n",
    "m_u = print_logit_scores(X_train_under, y_train_under, X_test, y_test, 'n', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сравните результаты со встроенной балансировкой на всей обучающей выборке\n",
    "# как вы думаете, какой есть сущесвтенный недостаток у undersampling по сравнению с балансировкой весов?\n",
    "m2 = print_logit_scores(X_train, y_train, X_test, y_test, 'b', w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача 8.4. Условие\n",
    "Загрузите датасеты Admission_train.csv и Admission_test.csv.\n",
    "\n",
    "Преобразуйте данные в столбце Chance of Admit в 0 и 1 по правилу: 0, если вероятность меньше 0.5, и 1, если больше либо равна 0.5. Удалите столбцы: Unnamed: 0 и Serial No.\n",
    "\n",
    "Выполните задания, которые приведены ниже:\n",
    "\n",
    "Задание 8.4.1\n",
    "\n",
    "Обучите логистическую регрессию по всем признакам без балансировки весов. Вычислите accuracy, чувствительность, специфичность, точность и ошибки 1 и 2 рода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>318</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>336</td>\n",
       "      <td>118</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>334</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        318          109                  3  3.5   4.0  9.22         1   \n",
       "1        336          118                  5  4.5   4.0  9.19         1   \n",
       "2        324          110                  3  3.5   3.0  9.22         1   \n",
       "3        334          120                  5  4.0   5.0  9.87         1   \n",
       "4        312          103                  3  3.5   4.0  8.78         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.68  \n",
       "1              0.92  \n",
       "2              0.89  \n",
       "3              0.97  \n",
       "4              0.67  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Импортируем датасет и избавимся от нулевых строк\n",
    "df_train = pd.read_csv('Admission_train.csv')\n",
    "#df_train.dropna(axis=0,inplace=True) #избавляемся от строчек с пропущенными значениями\n",
    "df_train.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "df_train.drop(['Serial No.'], axis=1, inplace=True)\n",
    "\n",
    "df_test = pd.read_csv('Admission_test.csv')\n",
    "#df_test.dropna(axis=0,inplace=True)\n",
    "df_test.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "df_test.drop(['Serial No.'], axis=1, inplace=True)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE</th>\n",
       "      <th>TOEFL</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>324</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>314</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>295</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>324</td>\n",
       "      <td>111</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8.79</td>\n",
       "      <td>1</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>297</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE  TOEFL  University Rating  SOP  LOR  CGPA  Research  Chance\n",
       "0  324    111                  5  4.5  4.0  9.16         1    0.90\n",
       "1  314    107                  3  3.0  3.5  8.17         1    0.73\n",
       "2  295     99                  1  2.0  1.5  7.57         0    0.37\n",
       "3  324    111                  3  2.5  1.5  8.79         1    0.70\n",
       "4  297    100                  1  1.5  2.0  7.90         0    0.52"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns=['GRE', 'TOEFL', 'University Rating', 'SOP', 'LOR', 'CGPA', 'Research', 'Chance']\n",
    "df_test.columns=['GRE', 'TOEFL', 'University Rating', 'SOP', 'LOR', 'CGPA', 'Research', 'Chance']\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    if x<0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE</th>\n",
       "      <th>TOEFL</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>324</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>314</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>295</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>324</td>\n",
       "      <td>111</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>297</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE  TOEFL  University Rating  SOP  LOR  CGPA  Research  Chance\n",
       "0  324    111                  5  4.5  4.0  9.16         1       1\n",
       "1  314    107                  3  3.0  3.5  8.17         1       1\n",
       "2  295     99                  1  2.0  1.5  7.57         0       0\n",
       "3  324    111                  3  2.5  1.5  8.79         1       1\n",
       "4  297    100                  1  1.5  2.0  7.90         0       1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=df_train.Chance.apply(func)\n",
    "df_train.Chance=train\n",
    "\n",
    "test=df_test.Chance.apply(func)\n",
    "df_test.Chance=test\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_train.drop('Chance', axis = 1)\n",
    "y_train=df_train[['Chance']]\n",
    "X_test=df_test.drop('Chance', axis = 1)\n",
    "y_test=df_test[['Chance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.LogisticRegression(solver='liblinear', class_weight=None) \n",
    "# обучаем\n",
    "model = lm.fit(X_train, y_train.values.ravel()) \n",
    "# сделаем prediction классов на всей тестовой выборке\n",
    "y_pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  6],\n",
       "       [ 3, 88]], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# строим confusion matrix - таблицу правильных и неправильных предсказаний\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.91\n",
      "Sensitivity:  0.967032967032967\n",
      "Specificity:  0.3333333333333333\n",
      "Pricision:  0.9361702127659575\n",
      "Type I error rate:  0.6666666666666666\n",
      "Type II error rate:  0.03296703296703297\n"
     ]
    }
   ],
   "source": [
    "TN = cnf_matrix[0,0] # True Negative\n",
    "TP = cnf_matrix[1,1] # True Positive\n",
    "FN = cnf_matrix[1,0] # False Negative\n",
    "FP = cnf_matrix[0,1] # False Positive\n",
    "    \n",
    "Ac = lm.score(X_test, y_test)\n",
    "Sens = TP/(TP+FN) \n",
    "Sp = TN/(TN+FP)\n",
    "P = TP/(TP+FP)\n",
    "typeI = FP/(FP+TN)\n",
    "typeII = FN/(FN+TP)\n",
    "    \n",
    "print('Accuracy: ', Ac)\n",
    "print('Sensitivity: ', Sens)\n",
    "print('Specificity: ', Sp)\n",
    "print('Pricision: ', P)\n",
    "print('Type I error rate: ', typeI)\n",
    "print('Type II error rate: ', typeII)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 8.4.2\n",
    " \n",
    "Обучите логистическую регрессию по всем признакам со встроенной балансировкой весов. Вычислите на тестовой выборке Accuracy, чувстительность, специфичность, точность, вероятности ошибок 1 и 2 рода.\n",
    "\n",
    "Ответы округлите до 4 знаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.LogisticRegression(solver='liblinear', class_weight='balanced') \n",
    "# обучаем\n",
    "model = lm.fit(X_train, y_train.values.ravel()) \n",
    "# сделаем prediction классов на всей тестовой выборке\n",
    "y_pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  2],\n",
       "       [20, 71]], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.78\n",
      "Sensitivity:  0.7802197802197802\n",
      "Specificity:  0.7777777777777778\n",
      "Pricision:  0.9726027397260274\n",
      "Type I error rate:  0.2222222222222222\n",
      "Type II error rate:  0.21978021978021978\n"
     ]
    }
   ],
   "source": [
    "TN = cnf_matrix[0,0] # True Negative\n",
    "TP = cnf_matrix[1,1] # True Positive\n",
    "FN = cnf_matrix[1,0] # False Negative\n",
    "FP = cnf_matrix[0,1] # False Positive\n",
    "    \n",
    "Ac = lm.score(X_test, y_test)\n",
    "Sens = TP/(TP+FN) \n",
    "Sp = TN/(TN+FP)\n",
    "P = TP/(TP+FP)\n",
    "typeI = FP/(FP+TN)\n",
    "typeII = FN/(FN+TP)\n",
    "    \n",
    "print('Accuracy: ', Ac)\n",
    "print('Sensitivity: ', Sens)\n",
    "print('Specificity: ', Sp)\n",
    "print('Pricision: ', P)\n",
    "print('Type I error rate: ', typeI)\n",
    "print('Type II error rate: ', typeII)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
