{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задания по уроку 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все задания выполняются на основе датасета UCI ML Breast Cancer Wisconsin. (https://goo.gl/U2Uwz2)  \n",
    "Все признаки являются числовыми."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи с проверкой кода\n",
    "\n",
    "1) Реализовать функцию подсчета индекса Джини"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gini_impurity(labels):\n",
    "    \"\"\"\n",
    "    :arg labels: np.array of shape (n_objects,)\n",
    "    \n",
    "    :return: gini_impurity: float\n",
    "    \"\"\"\n",
    "    # TODO your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gini_impurity(labels):\n",
    "    \"\"\"\n",
    "    :arg labels: np.array of shape (n_objects,)\n",
    "    \n",
    "    :return: gini_impurity: float\n",
    "    \"\"\"\n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    gini_impurity=0\n",
    "    for count in counts:\n",
    "        gini_impurity=gini_impurity+(count/np.shape(labels)[0])*(1-(count/np.shape(labels)[0]))\n",
    "    return gini_impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=np.array([1,1,1,1,3,3,3,3,3,3,5,5,5,5,5,5,7,7,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7423822714681441"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_gini_impurity(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels, counts = np.unique(y, return_counts=True)\n",
    "class_label = labels[counts.argmax(axis=0)]\n",
    "class_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Реализовать функцию подсчета энтропии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy(labels):\n",
    "    \"\"\"\n",
    "    :arg labels: np.array of shape (n_objects,)\n",
    "    \n",
    "    :return: entropy: float\n",
    "    \"\"\"\n",
    "    # TODO your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy(labels):\n",
    "    \"\"\"\n",
    "    :arg labels: np.array of shape (n_objects,)\n",
    "    \n",
    "    :return: entropy: float\n",
    "    \"\"\"\n",
    "    _,counts = np.unique(labels, return_counts=True)\n",
    "    entropy=0\n",
    "    probs=counts/len(labels)\n",
    "    for prob in probs:\n",
    "        entropy=entropy-prob*np.log2(prob)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=np.array([5, 6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_entropy(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Реализовать функцию подсчета Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_information_gain(s0, *args):\n",
    "    \"\"\"\n",
    "    Calculates IG for a split s_1, ..., s_k.\n",
    "        :arg s0: the whole set, sequence of shape (n_objects,)\n",
    "        :arg args: split — a list of sequences, such that s0 = union(s_1, ..., s_k) and\n",
    "           for all i, j: intersection(s_i, s_j) = 0\n",
    "           \n",
    "        :return: information_gain: float\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9182958340544896"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_information_gain([1, 2, 3, 4, 5, 6],\n",
    "                           [1, 2, 3, 4], [5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_information_gain(s0, *args):\n",
    "    \"\"\"\n",
    "    Calculates IG for a split s_1, ..., s_k.\n",
    "        :arg s0: the whole set, sequence of shape (n_objects,)\n",
    "        :arg args: split — a list of sequences, such that s0 = union(s_1, ..., s_k) and\n",
    "           for all i, j: intersection(s_i, s_j) = 0\n",
    "           \n",
    "        :return: information_gain: float\n",
    "    \"\"\"\n",
    "    _,counts0 = np.unique(s0, return_counts=True)\n",
    "    entropy0=0\n",
    "    probs0=counts0/len(s0)\n",
    "    for prob in probs0:\n",
    "        entropy0=entropy0-prob*np.log2(prob)  \n",
    "    \n",
    "    entropy_args=0    \n",
    "    for arg in args:\n",
    "        _,counts = np.unique(arg, return_counts=True)\n",
    "        entropy=0\n",
    "        probs=counts/len(arg)\n",
    "        for prob in probs:\n",
    "            entropy=entropy-prob*np.log2(prob)\n",
    "        entropy_args=entropy_args+entropy*(len(arg)/len(s0))\n",
    "          \n",
    "    information_gain=entropy0-entropy_args \n",
    "    \n",
    "    return information_gain  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_information_gain(s0, *args):\n",
    "    \"\"\"\n",
    "    Calculates IG for a split s_1, ..., s_k.\n",
    "        :arg s0: the whole set, sequence of shape (n_objects,)\n",
    "        :arg args: split — a list of sequences, such that s0 = union(s_1, ..., s_k) and\n",
    "           for all i, j: intersection(s_i, s_j) = 0\n",
    "           \n",
    "        :return: information_gain: float\n",
    "    \"\"\"\n",
    "    entropy0=compute_entropy(s0)  \n",
    "    \n",
    "    entropy_args=0    \n",
    "    for arg in args:\n",
    "        entropy=compute_entropy(arg)\n",
    "        entropy_args=entropy_args+entropy*(len(arg)/len(s0))\n",
    "          \n",
    "    information_gain=entropy0-entropy_args \n",
    "    \n",
    "    return information_gain  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9182958340544896"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_information_gain([1, 2, 3, 4, 5, 6],\n",
    "                           [1, 2, 3, 4], [5, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Реализовать функцию для выполнения преобразования \"mean encoding\" — замены индекса категориального признака на среднее по значениям целевой переменной в обучающей выборке, соответствующим этому индексу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# рекомендовали использовать groupby, но я сделала иначе\n",
    "def compute_mean_encoding(g0, g1):\n",
    "    df=pd.DataFrame({'col1':g0, 'col2':g1})\n",
    "    s=df['col1'].value_counts()\n",
    "    col11=[]\n",
    "    col22=[]\n",
    "    for i in s.index.sort_values(ascending=True):\n",
    "        col11.append(i)\n",
    "        col22.append(df[df.col1==i].col2.mean())\n",
    "    cat_feature=pd.Series(col22, index=col11, name='cat_feature')\n",
    "    return cat_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.55\n",
       "2    1.10\n",
       "3    1.65\n",
       "Name: cat_feature, dtype: float64"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_mean_encoding([  1, 1,   2, 2,   3, 3],\n",
    "                      [0.1, 1, 0.2, 2, 0.3, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи с проверкой ответа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Какой параметр дерева решений в Scikit-Learn отвечает за ограничение на минимальное количество объектов в листе дерева при его построении?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  min_samples_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Какой параметр дерева решений в Scikit-Learn отвечает за ограничение на минимальное количество объектов, подверженных сплиту, при его построении дерева?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  min_samples_split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Какой параметр дерева решений в Scikit-Learn отвечает за ограничение на максимальное количество листьев, которое получается при его построении дерева?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  max_leaf_nodes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В следующих заданих требуется так или иначе изменить параметры дерева решений и оценить результат.  \n",
    "Как метрику качества будем использовать F1-score. В каждом задании необходимо поменять __только один__ параметр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric(clf):\n",
    "    np.random.seed(42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    return np.round(f1_score(y_test, y_test_pred), 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем значение метрики со стандартными параметрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.957746"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metric(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Добавьте следующее условие: для выполнения сплита должно быть как минимум 22 объекта. Чему равна метрика F1 на отложенной выборке?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.951049"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metric(DecisionTreeClassifier(min_samples_split=22))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Добавьте следующее условие: в листе должно быть как минимум 10 элементов. Чему равна метрика F1 на отложенной выборке?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.958333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metric(DecisionTreeClassifier(min_samples_split=22, min_samples_leaf=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Добавьте следующее условие: в дереве должно быть не более 8 листьев. Чему равна метрика F1 на отложенной выборке?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.965035"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metric(DecisionTreeClassifier(max_leaf_nodes=8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Добавьте следующее условие: глубина дерева должна быть не более 4. Чему равна метрика F1 на отложенной выборке?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.957746"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metric(DecisionTreeClassifier(max_depth=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) При помощи параметра \"class_weight\" выставите веса объектов обратно пропорциональными их частоте в обучающей выборке. Чему стала равна метрика F1 на отложенной выборке?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.971831"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metric(DecisionTreeClassifier(class_weight='balanced'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Поменяйте критерий для построения дерева решений на 'entropy', который мы разбирали на теории. Чему стала равна метрика F1 на отложенной выборке?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.958904"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metric(DecisionTreeClassifier(criterion='entropy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Укажите параметр min_samples_split=50. Какая получилась глубина у получившегося дерева? Укажите ее ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 50,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'presort': False,\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTreeClassifier(min_samples_split=50).get_params()  #не вышло"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTreeClassifier(max_depth=10).get_params()['max_depth'] # работает так, но не влияет на следующее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric1(clf):\n",
    "    np.random.seed(42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    return clf.get_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metric1(DecisionTreeClassifier(min_samples_split=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) Вставьте в код условие, которое выполнит эвристику `min_samples_split`.\n",
    "\n",
    "```python\n",
    "class DecisionTreeClassifier(object):\n",
    "    def __init__(self, max_depth=3, min_samples_split=2, min_samples_leaf=1):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        \n",
    "        self.root = None\n",
    "    \n",
    "    def _fit_id3(self, x, y, level):\n",
    "        class_labels = np.unique(y)\n",
    "        # if there is only one class in y then return leaf node\n",
    "        if class_labels.size == 1:\n",
    "            self.n_nodes += 1\n",
    "            return Node(class_label=class_labels[0])\n",
    "\n",
    "        # find the most informative predicate and split by them\n",
    "        beta = Predicate(x, y)\n",
    "        to_left, to_right = beta.split(x, y)\n",
    "\n",
    "        # if one of arrays is empty after split then return leaf node\n",
    "        if (to_left[0].size == 0 or \n",
    "            to_right[0].size == 0 or \n",
    "            level > self.max_depth or\n",
    "            _____________________):\n",
    "            labels, counts = np.unique(y, return_counts=True)\n",
    "            class_label = labels[counts.argmax(axis=0)]\n",
    "            self.n_nodes += 1\n",
    "            return Node(class_label=class_label)\n",
    "\n",
    "        node = Node()\n",
    "        node.set_predicate(beta)\n",
    "\n",
    "        node.set_left(self._fit_id3(to_left[0], to_left[1], level + 1))\n",
    "        node.set_right(self._fit_id3(to_right[0], to_right[1], level + 1))\n",
    "\n",
    "        return node\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(x) < self.min_samples_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) Вставьте в код условие, которое выполнит эвристику `min_samples_leaf`.\n",
    "\n",
    "```python\n",
    "class DecisionTreeClassifier(object):\n",
    "    def __init__(self, max_depth=3, min_samples_split=2, min_samples_leaf=1):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        \n",
    "        self.root = None\n",
    "    \n",
    "    def _fit_id3(self, x, y, level):\n",
    "        class_labels = np.unique(y)\n",
    "        # if there is only one class in y then return leaf node\n",
    "        if class_labels.size == 1 or len(x) < _________________ :\n",
    "            self.n_nodes += 1\n",
    "            return Node(class_label=class_labels[0])\n",
    "\n",
    "        # find the most informative predicate and split by them\n",
    "        beta = Predicate(x, y)\n",
    "        to_left, to_right = beta.split(x, y)\n",
    "\n",
    "        # if one of arrays is empty after split then return leaf node\n",
    "        if (to_left[0].size == 0 or \n",
    "            to_right[0].size == 0 or \n",
    "            level > self.max_depth):\n",
    "            labels, counts = np.unique(y, return_counts=True)\n",
    "            class_label = labels[counts.argmax(axis=0)]\n",
    "            self.n_nodes += 1\n",
    "            return Node(class_label=class_label)\n",
    "\n",
    "        node = Node()\n",
    "        node.set_predicate(beta)\n",
    "\n",
    "        node.set_left(self._fit_id3(to_left[0], to_left[1], level + 1))\n",
    "        node.set_right(self._fit_id3(to_right[0], to_right[1], level + 1))\n",
    "\n",
    "        return node\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(x) < self.min_samples_leaf "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
