{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Линейная регрессия. Реализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_boston()\n",
    "data['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Реализация линейной регрессии с использованием матричных операций"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия выражается следующей зависимостью:\n",
    "$$y=X\\theta+\\epsilon,$$\n",
    "где $X$ — матрица объекты-признаки, $y$ — вектор целевых значений, соответствующих $X$, $\\theta$ — параметр линейной регрессии, $\\epsilon$ — некоторый шум."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из данного следует выражение для $\\theta$ как:\n",
    "$$X^Ty=X^TX\\theta \\rightarrow \\theta=(X^TX)^{-1}X^Ty$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем выражение для $\\theta$ с помощью операций линейной алгебры библиотеки Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАДАЧА Реализовать функцию, осуществляющую матричные операции для получения theta\n",
    "def linreg_linear(X, y):\n",
    "    theta = np.linalg.inv(X.T@X).dot(X.T)@y\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовить данные\n",
    "\n",
    "X, y = data['data'], data['target']\n",
    "\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычислить параметр theta\n",
    "theta = linreg_linear(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделать предсказания для тренировочной выборки\n",
    "y_pred = X.dot(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_regression_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'MSE = {mse:.2f}, RMSE = {rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 21.89, RMSE = 4.68\n"
     ]
    }
   ],
   "source": [
    "# Посчитать значение ошибок MSE и RMSE для тренировочных данных\n",
    "print_regression_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбить выборку на train/valid, вычислить theta,\n",
    "# сделать предсказания и посчитать ошибки MSE и RMSE\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "theta = linreg_linear(X_train, y_train)\n",
    "y_pred = X_valid.dot(theta)\n",
    "y_train_pred = X_train.dot(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 26.00, RMSE = 5.10\n",
      "MSE = 21.36, RMSE = 4.62\n"
     ]
    }
   ],
   "source": [
    "print_regression_metrics(y_valid, y_pred)\n",
    "print_regression_metrics(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 21.89, RMSE = 4.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X,y)\n",
    "y_pred = lr.predict(X)\n",
    "print_regression_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Реализация линейной регрессии с использованием методов оптимизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для реализации линейной регрессии с помощью методов оптимизации будем использовать функцию ошибки **среднего квадратичного** ([Mean Squared Error](https://en.wikipedia.org/wiki/Mean_squared_error)), которая является выпуклой функцией в n-мерном пространстве $\\mathbb{R}^n$ и в общем виде выглядит следующим образом:\n",
    "$$MSE = \\frac{1}{n} * \\sum_{i=1}^{n}{(y_i - a(x_i))^2}.$$\n",
    "Здесь $x_i$ — вектор-признак $i$-го объекта обучающей выборки, $y_i$ — истинное значение для $i$-го объекта, $a(x)$ — алгоритм, предсказывающий для данного объекта $x$ целевое значение, $n$ — кол-во объектов в выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае линейной регрессии $MSE$ представляется как:\n",
    "$$MSE(X, y, \\theta) = \\frac{1}{2n} * \\sum_{i=1}^{n}{(y_i - \\theta^Tx_i)^2} = \\frac{1}{2n} \\lVert{y - X\\theta}\\rVert_{2}^{2}=\\frac{1}{2n} (y - X\\theta)^T(y - X\\theta),$$\n",
    "где $\\theta$ — параметр модели линейной регрессии, $X$ — матрица объекты-признаки, $y$ - вектор истинных значений, соответствующих $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем первый вариант представления функции ошибки и посчитаем ее градиент по параметру $\\theta$, предварительно переименовав $MSE$ в $L$:\n",
    "$$L=\\frac{1}{2n} * \\sum_{i=1}^{n}{(y_i - \\theta^Tx_i)^2}$$\n",
    "$$\\nabla L = \\frac{1}{n}\\sum_{i=1}^{n}{(\\theta^Tx_i - y_i) \\cdot x_i} = \\frac{1}{n}X^T(X\\theta - y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходя из полученного выражения градиента, реализуем алгоритм градиентного спуска:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализовать функцию вычисления градиента функции MSE\n",
    "\n",
    "def calc_mse_gradient(X, y, theta):\n",
    "    n = X.shape[0]\n",
    "    grad = 1. / n * X.transpose().dot(X.dot(theta) - y)\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализовать функцию, осуществляющую градиентный шаг\n",
    "# (функция должна содержать параметр величины шага alpha - learning rate)\n",
    "\n",
    "def gradient_step(theta, theta_grad, alpha):\n",
    "    return theta - alpha * theta_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализовать функцию цикла градиентного спуска с доп. параметрами\n",
    "# начального вектора theta и числа итераций\n",
    "\n",
    "def optimize(X, y, grad_func, start_theta, alpha, n_iters):\n",
    "    theta = start_theta.copy()\n",
    "    \n",
    "    for i in range(n_iters):\n",
    "        theta_grad = grad_func(X, y, theta)\n",
    "        theta = gradient_step(theta, theta_grad, alpha)\n",
    "    \n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбить таблицу данных на матрицы X и y\n",
    "X, y = data['data'], data['target']\n",
    "\n",
    "# Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "m = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимизировать параметр линейной регрессии theta на всех данных\n",
    "theta = optimize(X, y, calc_mse_gradient, np.ones(m), 0.001, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.31891427e+247, 7.38542912e+247, 8.95058180e+247, 5.06877366e+245,\n",
       "       4.21448022e+246, 4.62454777e+247, 5.28353598e+248, 2.65276630e+247,\n",
       "       8.18859653e+247, 3.26684487e+249, 1.38172850e+248, 2.63958173e+249,\n",
       "       9.87470759e+247])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 88.9762, 100.    ,  27.74  ,   1.    ,   0.871 ,   8.78  ,\n",
       "       100.    ,  12.1265,  24.    , 711.    ,  22.    , 396.9   ,\n",
       "        37.97  ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверить максимальные значения по каждому признаку в данных\n",
    "X.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n",
      "168.3704950393814\n"
     ]
    }
   ],
   "source": [
    "print(data['feature_names'][np.argmax(X.std(axis=0)) + 1])\n",
    "print(np.max(X.std(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализовать даннные с помощью стандартной нормализации\n",
    "X, y = data['data'], data['target']\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 9.9339306 , 3.80423444, 2.42256516, 3.66839786,\n",
       "       2.73234648, 3.55504427, 1.11749449, 3.96051769, 1.66124525,\n",
       "       1.79819419, 1.63882832, 0.44105193, 3.54877081])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "X.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимизировать theta на новых данных\n",
    "theta = optimize(X, y, calc_mse_gradient, np.ones(m), 0.01, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.25328063e+01, -9.21740195e-01,  1.07033639e+00,  1.06388396e-01,\n",
       "        6.86667316e-01, -2.05006416e+00,  2.68062168e+00,  1.40667969e-02,\n",
       "       -3.10608483e+00,  2.57511475e+00, -1.97802851e+00, -2.05725099e+00,\n",
       "        8.48690321e-01, -3.74025884e+00])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделать предсказания при полученных параметрах\n",
    "y_pred = X.dot(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 21.90, RMSE = 4.68\n"
     ]
    }
   ],
   "source": [
    "# Посчитать значение ошибок MSE и RMSE для тренировочных данных\n",
    "print_regression_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 19.61, RMSE = 4.43\n"
     ]
    }
   ],
   "source": [
    "# Разбить выборку на train/valid, оптимизировать theta,\n",
    "# сделать предсказания и посчитать ошибки MSE и RMSE\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "theta = optimize(X_train, y_train, calc_mse_gradient, np.ones(m), 0.01, 5000)\n",
    "y_pred = X_valid.dot(theta)\n",
    "\n",
    "print_regression_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 3.5.5 \n",
    "\n",
    "Очистите данные от строк, где значение признака B меньше 50. Какой получился RMSE ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()\n",
    "\n",
    "#Проверяем номер позиции для В - 11-я\n",
    "#data['feature_names'][11]\n",
    "\n",
    "# Очищаем данные от строк, где значение признака B меньше 50\n",
    "x_list=[]\n",
    "y_list=[]\n",
    "for i in range (0, 506):\n",
    "    if data['data'][i,11]>=50:           \n",
    "        x_list.append(data['data'][i])\n",
    "        y_list.append(data['target'][i])\n",
    "X_new=np.array(x_list)\n",
    "Y_new=np.array(y_list)\n",
    "\n",
    "# Нормализуем даннные с помощью стандартной нормализации\n",
    "X_new = (X_new- X_new.mean(axis=0)) / X_new.std(axis=0)\n",
    "\n",
    "# Добавляем фиктивный столбец единиц (bias линейной модели)\n",
    "X_new = np.hstack([np.ones(X_new.shape[0])[:, np.newaxis], X_new])\n",
    "m_new = X_new.shape[1]\n",
    "\n",
    "# Оптимизируем theta на новых данных\n",
    "theta = optimize(X_new, Y_new, calc_mse_gradient, np.ones(m_new), 0.01, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 21.79, RMSE = 4.67\n"
     ]
    }
   ],
   "source": [
    "# Сделать предсказания при полученных параметрах\n",
    "Y_new_pred = X_new.dot(theta)\n",
    "\n",
    "# Посчитать значение ошибок MSE и RMSE для тренировочных данных   - был принят этот RMSE\n",
    "print_regression_metrics(Y_new, Y_new_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 18.31, RMSE = 4.28\n"
     ]
    }
   ],
   "source": [
    "# Разбить выборку на train/valid, оптимизировать theta,\n",
    "# сделать предсказания и посчитать ошибки MSE и RMSE\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_new, Y_new, test_size=0.2)\n",
    "theta = optimize(X_train, y_train, calc_mse_gradient, np.ones(m_new), 0.01, 5000)\n",
    "Y_new_pred = X_valid.dot(theta)\n",
    "\n",
    "print_regression_metrics(y_valid, Y_new_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 3.5.6 \n",
    " \n",
    "Нормализуйте признаки и обучите линейную регрессию матричным методом. Какой получился RMSE ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовить данные\n",
    "data = load_boston()\n",
    "X, y = data['data'], data['target']\n",
    "\n",
    "# Нормализуем даннные с помощью стандартной нормализации\n",
    "X = (X- X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "# Добавляем фиктивный столбец единиц (bias линейной модели)\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "\n",
    "# Вычислить параметр theta \n",
    "theta = linreg_linear(X, y)\n",
    "\n",
    "# Сделать предсказания для тренировочной выборки\n",
    "y_pred = X.dot(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 21.89, RMSE = 4.68\n"
     ]
    }
   ],
   "source": [
    "# Посчитать значение ошибок MSE и RMSE для тренировочных данных\n",
    "print_regression_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 21.89, RMSE = 4.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X,y)\n",
    "y_pred = lr.predict(X)\n",
    "print_regression_metrics(y, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
